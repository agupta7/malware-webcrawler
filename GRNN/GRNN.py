import general 
import numpy as np
import math

def GRNN_train (X,Y,test):
	num_train_inst = len(X)
	num_features = len(X[0])
	num_neurons = 2#num_features
	S1 = np.zeros(len(test))
	S2 = np.zeros(len(test))

	for X_indx , instance in enumerate(X):
		sigma = general.Std (instance)#calling the function to compute std for current instance
		intance = np.array(instance)
#		for neuron in range (num_neurons):
		Diff_sqr_sum = np.zeros(len(test))
		for tst_indx, t_inst in enumerate(test): # computing the sum of sqaure differences for all instances
			diff= instance - np.array(t_inst)# fi differences
			diff  *= diff			# diff squared
			Diff_sqr_sum[tst_indx] = sum (diff)# sum the differences for each test instance 
 		
		hft_qi = (-0.5*Diff_sqr_sum)/(sigma*sigma) # g = - norm^2/2*sigma^2
		hft_qi = np.exp(hft_qi)		# hf_i = exp(g )
		
		S1 +=hft_qi # Sum( hf_i (t_q , t_i) )
		S2 += hft_qi*Y[X_indx] # Sum( hf_i (t_q , t_i) )*d_i

	Output = S2/S1
#	print Output
	return Output 

#################### this function performs the k-fold validation, and returns the avg accuracy
def K_Folds (K, X,Y):
        Range = len(X)//K
        cnt = 0 ;
	GRNN_acc = 0 
	for indx in range (0,len(X) , Range):
		print "Test num %d "%(cnt),
                test_D = np.array(X[indx:indx+Range])
		test_L =  np.array(Y[indx:indx+Range])

                train_D = np.concatenate (( X[0:indx], X[indx+Range:len(X)] ))
       	        train_L =np.concatenate ((Y[0:indx],Y[indx+Range:len(Y)]))

		output = GRNN_train(train_D,train_L,test_D)		
		GRNN_acc += general.Accuracy(output,test_L)
		cnt+=1
	return "\nAverage Accuracy: %0.3f" %(GRNN_acc/K)


def Main ():
	X, Y = general.Load_Data ("malware_dataset.csv")
	X,Y = general.shuffle_in_unison_scary (X,Y)
	#print K_Folds (len(X),X,Y)
	print K_Folds ( 5, X,Y)
	
	#Xtest, X, Ytest, Y = general.split(0.25,X,Y)
	#print "SHAPE: test,train ",np.shape(Xtest)," ",np.shape(X)
	#output = GRNN_train(X,Y, Xtest)
	#general.Accuracy(output,Ytest)
	 
Main()
