import general 
import numpy as np
import math
import copy
import sys 
import random

def add_dimension(X):
	Norm = np.array([ np.sqrt( sum( np.square(item) ) ) for item in X ] )
	R_sqr = int (max(Norm) )+ 1
	New_feature = np.sqrt(R_sqr - Norm).reshape(len(X),1)
	X = np.append ( X ,New_feature,1).reshape (len(X), len(X[0])+1)
	return X 

def Norm(X):
        Mean = np.zeros(len(X[0]) ,dtype=float)
        Dev = np.zeros(len(X[0]) ,dtype=float)

        # normalizing on each feature
        for i in range (len(X[0])):
                Mean[i] = np.mean (X[:,i])
                Dev[i] =  np.std(X[:,i])

        res = Dev     # Normalizing the data
        return min(Dev)

def GRNN_train (X,Y,test, sigma):		
	num_train_inst = len(X);	num_features = len(X[0])
	S1 = np.zeros(len(test));	S2 = np.zeros(len(test))

#	X = add_dimension (X);	test = add_dimension (test)	

	for X_indx , instance in enumerate(X):
		instance = np.array(instance)
		Diff_sqr_sum = np.zeros(len(test))
		for tst_indx, t_inst in enumerate(test): # computing the sum of sqaure differences for all instances
			diff= instance - np.array(t_inst)# fi differences
			diff  *= diff			# diff squared
			Diff_sqr_sum[tst_indx] = sum (diff)# sum the differences for each test instance 
 			
		hft_qi = (-0.5*Diff_sqr_sum)/(sigma*sigma) # g = - norm^2/2*sigma^2
		hft_qi = np.exp(hft_qi)		# hf_i = exp(g )
		
		S1 +=hft_qi # Sum( hf_i (t_q , t_i) )
		S2 += hft_qi*Y[X_indx] # Sum( hf_i (t_q , t_i) )*d_i

	Output = S2/S1

	return Output 

#################### this function performs the k-fold validation, and returns the avg accuracy
def K_Folds (K, X,Y, sigma):
        Range = len(X)/K ;        cnt = 1 ;	indx = 0 ; 
	GRNN_acc = 0 ;	FP = 0; FN = 0; TP = 0 ; TN = 0 

	for k in range (K):
                test_D = np.array(X[indx:indx+Range])
		test_L =  np.array(Y[indx:indx+Range])
                train_D = np.concatenate (( X[0:indx], X[indx+Range:len(X)] ))
       	        train_L =np.concatenate ((Y[0:indx],Y[indx+Range:len(Y)]))
		indx += Range

		output = GRNN_train(train_D,train_L,test_D, sigma)		
		acc, fp, fn, tp , tn  = general.Accuracy(output,test_L)
		FP += fp 	; FN += fn;	  GRNN_acc += acc;
		TP += tp ; TN += tn 
		cnt+=1

	print "Accuracy: %f , FP: %d , FN: %d, TP: %d , TN %d"%(GRNN_acc/K,FP,FN,TP,TN)	
	return GRNN_acc/K , FP, FN, TP , TN

def Main (X, Y, sigma):	
	for i in range (1):
		print "Sigma= ",sigma 
		Avg_acc , Avg_FP, Avg_FN , TP , TN = K_Folds ( len(X), X,Y ,sigma) 
 		print 
	return Avg_acc

def Predict (X,Y,sigma, unigrames):
	file = open ("GrNN.txt","w")
#	print "IN predict, unigrames looks like this: \n",unigrames
	Test = np.array(unigrames)
#	Test = general.Normalization_min_max(Test)
	Test= general.standarize(Test)
	output =  GRNN_train (X,Y,Test,sigma)

	for indx, item in enumerate( output) :
#		print indx, " ",item 
		file.write ("indx %d item %f"%(indx,item))
	file.close()

	return output

def treeToList(unigramTree, unigramList):
	unigramList = unigramList or []
	if unigramTree is None:
        	return []
    	for link in (unigramTree['links'] or []):
        	unigramList.append(link)
        	treeToList(link, unigramList)
    
    	return unigramList

def Test_from_pickle (X,Y,sigma, unigrame_File_name):# pickle file should contain a tree 
        import pickle
        file_unigrames = pickle.load( open(unigrame_File_name,"rb"))
        unigrames = []
        unigrames = treeToList(file_unigrames, unigrames)

        Unis = []
        for link in unigrames:
                Unis.append(link['unigram'])

        output= Predict (X,Y,sigma,np.array(Unis))
        return output
	
if __name__ == "__main__":
	    #X, Y = general.Load_Data ("malware_dataset.csv")
	    X,Y= general.Load_Data ("dataset_added.csv")
	    X,Y =  general.Modify_dataset (X,Y)
	    X,Y = general.shuffle_in_unison_scary (X,Y)
	    X = general.Normalization_min_max (X)
	    #X = general.standarize(X)
	    sigma = 0.246711580707
	    Main (X,Y,sigma)

class GRNNPredictor:
	def __init__(self, dataset, sigma):
	        self.X, self.Y = GRNNPredictor.loadDataset(dataset)
	        #self.X = general.Normalization_min_max(self.X)
	        self.sigma = sigma

	def predict(self, featureVector):
                X_copy = list(copy.deepcopy(self.X))
                X_copy.append(np.array(featureVector))
                X_copy = general.Normalization_min_max(np.array(X_copy))
                output = GRNN_train(X_copy[:-1], self.Y, X_copy[-1:], self.sigma)
        	return output[0]

	@classmethod
	def loadDataset(cls, fileName):
        	return general.Load_Data(fileName)
