import general 
import numpy as np
import math
from sklearn import datasets
import sys 
import random

def add_dimension(X):
	Norm = np.array([ np.sqrt( sum( np.square(item) ) ) for item in X ] )
	R_sqr = int (max(Norm) )+ 1
	New_feature = np.sqrt(R_sqr - Norm).reshape(len(X),1)
	X = np.append ( X ,New_feature,1).reshape (len(X), len(X[0])+1)
	return X 

def Norm(X):
        Mean = np.zeros(len(X[0]) ,dtype=float)
        Dev = np.zeros(len(X[0]) ,dtype=float)

        # normalizing on each feature
        for i in range (len(X[0])):
                Mean[i] = np.mean (X[:,i])
                Dev[i] =  np.std(X[:,i])

        res = Dev     # Normalizing the data
        return min(Dev)

def GRNN_train (X,Y,test, sigma):		
	num_train_inst = len(X)
	num_features = len(X[0])
	S1 = np.zeros(len(test))
	S2 = np.zeros(len(test))
#	sigma = Norm(X)
#	sigma =  0.11853 #1.41

#	X = add_dimension (X)
#	test = add_dimension (test)	
#	print "SHAPES:, ",np.shape(X), np.shape(test)
	for X_indx , instance in enumerate(X):
#		sigma = general.Std (instance)#calling the function to compute std for current instance
		instance = np.array(instance)
#		print instance 
#		print t_inst
		Diff_sqr_sum = np.zeros(len(test))
		for tst_indx, t_inst in enumerate(test): # computing the sum of sqaure differences for all instances
			diff= instance - np.array(t_inst)# fi differences
			diff  *= diff			# diff squared
			Diff_sqr_sum[tst_indx] = sum (diff)# sum the differences for each test instance 
 			
		hft_qi = (-0.5*Diff_sqr_sum)/(sigma*sigma) # g = - norm^2/2*sigma^2
		hft_qi = np.exp(hft_qi)		# hf_i = exp(g )
		
		S1 +=hft_qi # Sum( hf_i (t_q , t_i) )
		S2 += hft_qi*Y[X_indx] # Sum( hf_i (t_q , t_i) )*d_i

	Output = S2/S1

	return Output 

#################### this function performs the k-fold validation, and returns the avg accuracy
def K_Folds (K, X,Y, sigma):
#	print "K fold validation with K= %d"%K
        Range = len(X)/K 
        cnt = 1 ;
	GRNN_acc = 0 
	FP = 0 
	FN = 0 
	TP = 0 ; TN = 0 
	score= 0
	indx = 0 ; 
#	for indx in range (0,len(X) , Range):
	for k in range (K):
#		print "Test fold num %d "%(cnt),
                test_D = np.array(X[indx:indx+Range])
		test_L =  np.array(Y[indx:indx+Range])
                train_D = np.concatenate (( X[0:indx], X[indx+Range:len(X)] ))
       	        train_L =np.concatenate ((Y[0:indx],Y[indx+Range:len(Y)]))
		indx += Range
#		print " test Size: ", np.shape(test_D), " train size: ",np.shape(train_D)		
		output = GRNN_train(train_D,train_L,test_D, sigma)		
		acc, fp, fn, tp , tn  = general.Accuracy(output,test_L)
		FP += fp 	; FN += fn;	  GRNN_acc += acc;
		TP += tp ; TN += tn 
		cnt+=1

	print "Accuracy: %f , FP: %d , FN: %d, TP: %d , TN %d"%(GRNN_acc/K,FP,FN,TP,TN)	
	return GRNN_acc/K , FP, FN, TP , TN

def Main (X, Y, sigma):	
	for i in range (1):
		print sigma 
		Avg_acc , Avg_FP, Avg_FN , TP , TN = K_Folds ( len(X), X,Y ,sigma) 
 		print 
	return Avg_acc

def Predict (X,Y,sima, unigrames):
	file = open ("GrNN.txt","w")
	Test = np.array(unigrames)
	Test = general.Normalization_min_max(Test)
#	Test= general.standarize(Test)
	output =  GRNN_train (X,Y,Test,sigma)

#	print 
	for indx, item in enumerate( output) :
#		print indx, " ",item 
		file.write ("indx %d item %f"%(indx,item))
	file.close()

def treeToList(unigramTree, unigramList):
	unigramList = unigramList or []
	if unigramTree is None:
        	return []
    	for link in (unigramTree['links'] or []):
        	unigramList.append(link)
        	treeToList(link, unigramList)
    
    	return unigramList
	
#X, Y = general.Load_Data ("malware_dataset.csv")
X,Y= general.Load_Data ("dataset_added.csv")
X,Y = general.shuffle_in_unison_scary (X,Y)
X = general.Normalization_min_max (X)
#X = general.standarize(X)
sigma = 0.246711580707
Main (X,Y,sigma)
'''
import pickle 
wiki_unigrames = pickle.load( open("en.wikipedia.org.unigram","rb"))
unigrames = [] 
unigrames = treeToList(wiki_unigrames, unigrames)
Unis = [] 
for link in unigrames:
	Unis.append(link['unigram'])

Predict (X,Y,sigma,np.array(Unis))

'''
