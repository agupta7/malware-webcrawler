import general 
import numpy as np
import math
import sys 
import random

def add_dimension(X):
	Norm = np.array([ np.sqrt( sum( np.square(item) ) ) for item in X ] )
	R_sqr = int (max(Norm) )+ 1
	New_feature = np.sqrt(R_sqr - Norm).reshape(len(X),1)
	X = np.append ( X ,New_feature,1).reshape (len(X), len(X[0])+1)
	return X 

def Norm(X):
        Mean = np.zeros(len(X[0]) ,dtype=float)
        Dev = np.zeros(len(X[0]) ,dtype=float)

        # normalizing on each feature
        for i in range (len(X[0])):
                Mean[i] = np.mean (X[:,i])
                Dev[i] =  np.std(X[:,i])

        res = Dev     # Normalizing the data
        return min(Dev)

def GRNN_train (X,Y,test, sigma):		
	num_train_inst = len(X);	num_features = len(X[0])
	S1 = np.zeros(len(test));	S2 = np.zeros(len(test))

#	X = add_dimension (X);	test = add_dimension (test)	

	for X_indx , instance in enumerate(X):
		instance = np.array(instance)
		Diff_sqr_sum = np.zeros(len(test))
		for tst_indx, t_inst in enumerate(test): # computing the sum of sqaure differences for all instances
			diff= instance - np.array(t_inst)# fi differences
			diff  *= diff			# diff squared
			Diff_sqr_sum[tst_indx] = sum (diff)# sum the differences for each test instance 
 			
		hft_qi = (-0.5*Diff_sqr_sum)/(sigma*sigma) # g = - norm^2/2*sigma^2
		hft_qi = np.exp(hft_qi)		# hf_i = exp(g )
		
		S1 +=hft_qi # Sum( hf_i (t_q , t_i) )
		S2 += hft_qi*Y[X_indx] # Sum( hf_i (t_q , t_i) )*d_i

	Output = S2/S1

	return Output 

#################### this function performs the k-fold validation, and returns the avg accuracy
def K_Folds (K, X,Y, sigma):
        Range = len(X)/K ;        cnt = 1 ;	indx = 0 ; 
	GRNN_acc = 0 ;	FP = 0; FN = 0; TP = 0 ; TN = 0 

	for k in range (K):
                test_D = np.array(X[indx:indx+Range])
		test_L =  np.array(Y[indx:indx+Range])
                train_D = np.concatenate (( X[0:indx], X[indx+Range:len(X)] ))
       	        train_L =np.concatenate ((Y[0:indx],Y[indx+Range:len(Y)]))
		indx += Range

		output = GRNN_train(train_D,train_L,test_D, sigma)		
		acc, fp, fn, tp , tn  = general.Accuracy(output,test_L)
		FP += fp 	; FN += fn;	  GRNN_acc += acc;
		TP += tp ; TN += tn 
		cnt+=1

	print "Accuracy: %f , FP: %d , FN: %d, TP: %d , TN %d"%(GRNN_acc/K,FP,FN,TP,TN)	
	return GRNN_acc/K , FP, FN, TP , TN

def Main (X, Y, sigma):	
	for i in range (1):
		print "Sigma= ",sigma 
		Avg_acc , Avg_FP, Avg_FN , TP , TN = K_Folds ( len(X), X,Y ,sigma) 
 		print 
	return Avg_acc

def Predict (X,Y,sigma, unigrames):
	file = open ("GrNN.txt","w")
#	print "IN predict, unigrames looks like this: \n",unigrames
	Test = np.array(unigrames)
#	Test = general.Normalization_min_max(Test)
	Test= general.standarize(Test)
	output =  GRNN_train (X,Y,Test,sigma)

	for indx, item in enumerate( output) :
#		print indx, " ",item 
		file.write ("indx %d item %f"%(indx,item))
	file.close()

	return output

def treeToList(unigramTree, unigramList):
	unigramList = unigramList or []
	if unigramTree is None:
        	return []
    	for link in (unigramTree['links'] or []):
        	unigramList.append(link)
        	treeToList(link, unigramList)
    
    	return unigramList

def Test_from_pickle (X,Y,sigma, unigrame_File_name):# pickle file should contain a tree 
        import pickle
        file_unigrames = pickle.load( open(unigrame_File_name,"rb"))
        unigrames = []
        unigrames = treeToList(file_unigrames, unigrames)

        Unis = []
        for link in unigrames:
                Unis.append(link['unigram'])

        output= Predict (X,Y,sigma,np.array(Unis))
        return output
	
if __name__ == "__main__":
	    #X, Y = general.Load_Data ("malware_dataset.csv")
	    X,Y= general.Load_Data ("dataset_added.csv")
#	    X,Y =  general.Modify_dataset (X,Y)
	    X,Y = general.shuffle_in_unison_scary (X,Y)
	    X = general.Normalization_min_max (X)
	    #X = general.standarize(X)
	    sigma = 0.246711580707
#	    Main (X,Y,sigma)
#	    unigram = [0.048579494875, 0.000101737162042, 0.0367779840781, 0.000101737162042, 0.0, 0.000152605743063, 0.000584988681741, 0.00172953175471, 0.00178040033573, 0.00178040033573, 0.000279777195615, 0.000406948648167, 0.0021873489839, 0.035175623776, 0.00872396164509, 0.0271129536842, 0.0138108197472, 0.00750311570059, 0.00864765877356, 0.0103771905283, 0.00427296080576, 0.00638400691813, 0.00592618968894, 0.00701986418089, 0.00310298344228, 0.00503598952107, 0.00190757178828, 0.00251799476054, 0.031487651652, 0.019330060788, 0.0314622173614, 0.000152605743063, 0.0, 0.00139888597808, 0.00236538901747, 0.00228908614594, 0.00261973192258, 0.00129714881603, 0.00172953175471, 0.00323015489483, 0.00246712617952, 0.00254342905105, 0.00185670320726, 0.00307754915177, 0.0019330060788, 0.00310298344228, 0.00300124628024, 0.0012208459445, 0.00185670320726, 0.00114454307297, 0.00330645776636, 0.00516316097362, 0.00256886334156, 0.00109367449195, 0.002441691889, 0.00312841773279, 0.0026706005036, 0.00350993209044, 0.00386601215759, 0.00127171452552, 0.00513772668311, 0.00127171452552, 0.0, 0.000228908614594, 0.0, 0.0714703563344, 0.0125899738027, 0.0313604801994, 0.0309280972607, 0.036472772592, 0.0165831574128, 0.0133784368085, 0.0241117074039, 0.0417631050182, 0.0041203550627, 0.00529033242618, 0.043797848259, 0.0202456952463, 0.0296563827352, 0.0303685428695, 0.0204491695704, 0.000406948648167, 0.0271383879747, 0.050919449602, 0.0346669379658, 0.0179311748099, 0.012106722283, 0.00808810438233, 0.00780832718671, 0.00791006434875, 0.00198387465982, 0.000508685810209, 0.000228908614594, 0.000508685810209, 0.0]
#	    unigrame = np.array(unigram)
	    output =  Predict (X,Y,sigma,X)
	    print output
	    acc = general.Accuracy(output,Y)
	    print "accuracy:",acc

class GRNNPredictor:
	def __init__(self, dataset, sigma):
	        self.X, self.Y = GRNNPredictor.loadDataset(dataset)
	        self.X = general.Normalization_min_max(self.X)
#		self.X = general.standarize(self.X)
	        self.sigma = sigma

	def predict(self, featureVector):
        	output = GRNN_train(self.X, self.Y,general.Normalization_min_max(np.array(featureVector)), self.sigma)
        	return output

	@classmethod
	def loadDataset(cls, fileName):
        	return general.Load_Data(fileName)
