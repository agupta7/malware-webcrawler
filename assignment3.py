#!/usr/bin/python -uB
from WebCrawller import WebCrawller
import json
import weightedknn.weighted_knn as wknn
from assignment2 import loadDataset
import numpy as np
import sys
from Best_NN import iter_NN
import pickle

'''
    unigramList is a list from the output of WebCrawller.crawlIDS function.
    Each member contains the following properties:
        'url': The subject URL
        'unigram': The feature vector in question
'''
def findURLsInRange(dataset, unigramList, lower, upper):
    idealK = len(dataset)
    idealB = 5
    #idealFeatureMask = [ 2.79505473, -0.08261826,  1.13027223,  0.02900638, -0.41311526,  2.54375343,  1.73454424,  1.24928336,  2.29198577,  2.72990604,  2.74405648, -0.57972447,  3.88540623,  4.03388891, -0.69682703,  4.33082449,  3.15355936,  2.69883986,  3.70184423, -0.58332957,  0.18695502,  0.75615967,  0.38822057,  1.04596591, -0.93154375,  3.38413251,  2.95536754,  0.75063247,  1.73683827,  2.3931584,  4.66863766, -0.07333984,  0.99961988,  2.33591766,  0.94668458,  3.82414313,  0.78485549,  0.13003803,  1.87092418,  4.14245767,  2.89389834,  2.42368276,  0.43292411,  1.26622542,  1.08630463,  2.78998059,  1.72552944,  2.19254859,  4.34469519,  2.11511593,  3.37977035,  1.56606212,  0.43121118,  2.75870837, -0.22480478,  0.19446793, -0.05158749,  3.53512885,  4.7027534,  -0.57606933,  2.60159531,  0.91818027,  0.05633404,  1.11082689,  4.8587878,   3.47237735,  4.10243608, -0.70384068,  4.92262667,  2.20095389,  1.64843906,  3.72490837,  4.85699546,  3.77576413,  2.07993859,  0.82304504,  1.5069362,   4.3831959,  1.92058263,  1.84877895,  4.87165707,  2.7615372,  -0.05822481, -0.64069247,  4.94106717,  4.20333662,  2.8059968,   4.9139785,   4.55399224,  4.21666383,  0.16306578,  2.21921174,  2.74880612,  0.14758338,  1.66889131]
    idealFeatureMask = np.ones(95)

    knn = wknn.WeightedKnn(dataset, idealK, idealB, idealFeatureMask)
    for link in unigramList:
        prediction = knn.predict(link['unigram'])
        #prediction = iter_NN.General_Predict([link['unigram']])[0]
        if prediction > lower and prediction <= upper:
            print "URL {0} has a prediction of {1}".format(link['url'], prediction)

def treeToList(unigramTree, unigramList):
    unigramList = unigramList or []
    if unigramTree is None:
        return []
    for link in (unigramTree['links'] or []):
        unigramList.append(link)
        treeToList(link, unigramList)
    return unigramList

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print >> sys.stderr, "Usage: {0} dataset_file rootURL".format(sys.argv[0])
        sys.exit()
    dataset = loadDataset(sys.argv[1])
    rootURL = sys.argv[2]

    '''
    unigramTree has:
        'url': string
        'unigram': array of 95 numbers
        'links': array of recursive unigramTrees
    '''
    unigramTree = None
    if '.unigram' in rootURL:
        unigramTree = pickle.load(open(rootURL, 'rb'))
    else:
        unigramTree = json.loads(WebCrawller.crawlIDS(rootURL, 1)['json'])
        pickle.dump(unigramTree, open('url.unigram', 'wb'))


    print "----------- -1 to -0.5 ------------"
    findURLsInRange(dataset, treeToList(unigramTree, []), -1.0001, -0.5)
    print "----------- -0.5 to 0 ------------"
    findURLsInRange(dataset, treeToList(unigramTree, []), -0.50, 0)
    print "----------- 0 to 0.5 ------------"
    findURLsInRange(dataset, treeToList(unigramTree, []), 0, 0.5)
    print "----------- 0.5 to 1 ------------"
    findURLsInRange(dataset, treeToList(unigramTree, []), 0.50, 1)
