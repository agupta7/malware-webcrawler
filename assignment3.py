from WebCrawller import WebCrawller
import json
from assignment2 import loadDataset
import weighted_knn as wknn
import numpy as np

def findURLsInRange(dataset, unigramTree, lower, upper):
    idealK = len(dataset)
    idealB = 10
    idealFeatureMask = np.array([ -4.00000000e-02,  1.82500000e-01,  1.02500000e+00, -1.08750000e+00, -7.25000000e-02,  7.75000000e-02, -5.50000000e-02, -8.17500000e-01,  2.48000000e+00, -1.02500000e-01,  5.60000000e-01,  1.47250000e+00,  2.17000000e+00,  2.98500000e+00, -9.65000000e-01,  2.96250000e+00,  7.07500000e-01,  9.50000000e-02,  1.95000000e-01,  7.97500000e-01,  1.06500000e+00,  4.05000000e-01, -1.07750000e+00,  9.30000000e-01, -9.25000000e-01,  2.09000000e+00,  1.08750000e+00, -3.52500000e-01, -8.40000000e-01,  2.99250000e+00,  2.86750000e+00,  5.75000000e-02,  5.00000000e-03,  8.85000000e-01, -1.07750000e+00, -1.12000000e+00, -9.95000000e-01, -2.37500000e-01, -7.25000000e-02,  1.96500000e+00,  1.98000000e+00,  6.20000000e-01,  1.64250000e+00, -1.76750000e+00,  7.62500000e-01,  1.24000000e+00,  1.34000000e+00, -7.75000000e-02,  9.67500000e-01,  1.03250000e+00,  1.50000000e-02,  1.26750000e+00,  1.42500000e-01,  2.34000000e+00,  5.17500000e-01,  1.07000000e+00, -2.27500000e-01,  3.39750000e+00,  1.70500000e+00, -1.27250000e+00,  2.00750000e+00,  2.50000000e-03,  7.25000000e-02, -1.25000000e-01,  3.39000000e+00,  1.93500000e+00, -5.20000000e-01, -1.09750000e+00,  2.97750000e+00,  1.07000000e+00,  3.21750000e+00,  2.00750000e+00,  1.81000000e+00, -3.47500000e-01,  4.15000000e-01,  9.35000000e-01,  9.75000000e-02,  2.39250000e+00,  3.12500000e-01,  5.45000000e-01,  3.97000000e+00,  8.27500000e-01,  1.59500000e+00, -4.65000000e-01,  2.08750000e+00,  3.88000000e+00,  2.02500000e-01,  1.88500000e+00,  2.65500000e+00,  2.98250000e+00, -1.85000000e-01, -2.56000000e+00,  8.12500000e-01,  6.60000000e-01, -2.00000000e-01])

    knn = wknn.WeightedKnn(dataset)
    prediction = knn.predict(unigramTree['unigram'], idealK, idealB, idealFeatureMask)
    print str(prediction) + unigramTree['url']
    if prediction > lower and prediction <= upper:
        print "URL {0} has a prediction of {1}".format(unigramTree['url'], prediction)

    for link in (unigramTree['links'] or [ ]):
        findURLsInRange(dataset, link, lower, upper)


if __name__ == "__main__":
    dataset = loadDataset('dataset.csv')
    rootURL = "http://reddit.com"
    unigramTree = json.loads(WebCrawller.crawlIDS(rootURL, 1)['json'])
    findURLsInRange(dataset, unigramTree, 0.75, 1)
