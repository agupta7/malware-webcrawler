import web
from WebCrawller import WebCrawller

urls = (
    '/', 'Crawl',
    '/crawl', 'Crawl'
)

class Crawl:
    def GET(self):
        web.header('Content-Type', 'application/json')
        queryParams = web.input()
        # TODO : sanitize input parameters before handing them off to the crawler
        maxDepth = queryParams['maxDepth']
        return WebCrawller.crawl(queryParams.root, maxDepth or 10)

if __name__ == "__main__":
    app = web.application(urls, globals())
    app.run()
