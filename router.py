import web
from WebCrawller import WebCrawller

urls = (
    '/', 'Crawl',
    '/crawl', 'Crawl'
)

class Crawl:
    def GET(self):
        web.header('Content-Type', 'application/json')
        queryParams = web.input(maxDepth=3, root='auburn.edu')
        # TODO : sanitize input parameters before handing them off to the crawler
        return WebCrawller.crawlIDS(queryParams.root, int(queryParams.maxDepth))

if __name__ == "__main__":
    app = web.application(urls, globals())
    # TODO: To check if the port is available before trying to connect with the default port and give a
    # proper error message to the user
    app.run()
