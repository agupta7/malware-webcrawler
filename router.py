import web
from WebCrawller import WebCrawller

urls = (
    '/', 'Crawl',
    '/crawl', 'Crawl'
)

class Crawl:
    def GET(self):
        web.header('Content-Type', 'application/json')
        queryParams = web.input(maxDepth=3, root='auburn.edu')
        # TODO : sanitize input parameters before handing them off to the crawler
        return WebCrawller.crawlIDS(queryParams.root, queryParams.maxDepth)

if __name__ == "__main__":
    app = web.application(urls, globals())
    app.run()
