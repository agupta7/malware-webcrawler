class WebCrawllerPage:
    def __init__(self, url):
        self.url = url
        self.descendants = []
        self.unigram = None

    def buildUnigram(self, contents):
        # pick up contents from cache if not passed in
        pass

    def extractLinks(self, contents):
        # pick up contents from cache if not passed in
        pass

    def getContentsFromCache(self):
        pass

    def toJson(self, recursive):
            # need to get unigram and contents and stream it out to JSON
