import csv
import math
import operator 
import numpy as np
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import SelectFromModel
from sklearn.svm import LinearSVC

def shuffleDataset(dataset):
    np.random.shuffle(dataset)
    # print "Shuffled.."
    
    return dataset

def loadDataset(filename):
    with open(filename, 'rb') as csvfile:
        lines = csv.reader(csvfile)
        dataset = list(lines)

        for x in range(len(dataset)):
            for y in range(len(dataset[0])):
                dataset[x][y] = float(dataset[x][y])

    dataset = np.array(dataset, dtype=float)
    shuffleDataset(dataset)
    return dataset

def splitDataset(dataset, split):
    split1=[]
    split2=[]
    index = int(split*len(dataset))

    split1, split2 = np.split(dataset, [index] )

    return split1, split2, index

def manhattanDistance(instance1, instance2, length):
    distance = 0
    for x in range(2,length):
        distance += abs((instance1[x] - instance2[x]))
    return distance

def squareEuclideanDistance(instance1, instance2, length):
    distance = 0
    for x in range(1,length):
        distance += pow((instance1[x] - instance2[x]), 2)
    return distance

def minkowskiDistance(instance1, instance2, length, p):
    distance = 0
    for x in range(1,length):
        distance += pow(abs((instance1[x] - instance2[x])), p)
    return pow(distance, (1/p))

def halfEuclideanDistance(instance1, instance2, length):
    distance = 0
    for x in range(1,length):
        distance += pow((instance1[x] - instance2[x]), 2)
    return 0.5*distance

def chebyshevDistance(instance1, instance2, length):
    distance = []
    for x in range(2,length):
        distance.append(abs((instance1[x] - instance2[x])))
    return min(distance)

def getNeighbors(trainingSet, testInstance, k):
    distances = []
    length = len(testInstance)

    for x in range(len(trainingSet)):
        # dist = manhattanDistance(testInstance, trainingSet[x], length)
        dist = minkowskiDistance(testInstance, trainingSet[x], length, 0.25)
        #print "----------------Distance:"+repr(dist)
        distances.append((trainingSet[x], dist))
    distances.sort(key=operator.itemgetter(1))
    #print distances
    neighbors = []
    for x in range(k):
        neighbors.append(distances[x][0])
    return neighbors

def getResponseDiscrete(neighbors):
    classVotes = {}
    for x in range(len(neighbors)):
        response = neighbors[x][0]
        if response in classVotes:
            classVotes[response] += 1
        else:
            classVotes[response] = 1
    sortedVotes = sorted(classVotes.iteritems(), key=operator.itemgetter(1), reverse=True)
    return sortedVotes[0][0]

def getResponseContinuous(neighbors):
    response = 0
    for x in range(len(neighbors)):
        response += neighbors[x][0]
    return (response/(len(neighbors)))

####################  this function returns the std for a single data instance 
def Std (instance):
    mean = sum(instance)/float(len(instance))
    dif_sqr = [math.pow(feature-mean,2) for feature in instance ]
    dif_mean =  sum(dif_sqr)/float(len(dif_sqr))    
    std = math.sqrt(dif_mean)
    return std 

def Normalization (X):
        # print "Normalizing Data:\n"
        Mean = np.zeros(len(X[0]),dtype=float)
        Dev = np.zeros(len(X[0]),dtype=float)

        # normalizing on each feature
        for i in range (len(X[0])):
            Mean[i] = np.mean (X[:,i])
            Dev[i] =  Std(X[:,i])
        
        X = ( X - Mean)/Dev     # Normalizing the data
        #print "MEAN: ", Mean
        #print "---------------------------------"
        #print "DEV: ", Dev
        return X

def Normalization_min_max(X):
        x_min = np.zeros(len(X[0]) ,dtype=float)
        x_max= np.zeros(len(X[0]) ,dtype=float)

        for i in range( len(X[0])):
                x_min[i] = min (X[:,i])
                x_max[i] = max (X[:,i])

        X = (X - x_min)/(x_max - x_min)
        return X

def SVM_Feature_Select(X,Y, c):
        # print "c :",c
        lsvc = LinearSVC(C = c , penalty="l1", dual=False).fit(X,Y)
        model= SelectFromModel(lsvc , prefit=True)
        X = model.transform(X)
        # print "featured Extracted: ",X.shape
        return X

def Variance_Feature_Select(X):
        sel = VarianceThreshold(threshold=(.85 * (1 - .85)))
        X = sel.fit_transform(X)
        # print "featured Extracted: ",X.shape
        return X

def main():
    #Repeat the process 5 times to get better results:
    avg_accuracy = 0.0
    avg_fp = 0
    avg_fn = 0
    avg_tp = 0
    avg_tn = 0
    for index in range(5):
        dataset = loadDataset('malware_dataset_old.csv')
        indices = []
        X = np.delete(dataset, [0,1], 1)  # delete first 2 columns of C
        Y = np.delete(dataset, 0, 1)  # delete first column of C
        for index in range(1,len(Y[0])):
            indices.append(index)
        Y = np.delete(Y, indices, 1)  # delete first column of C
        X = Normalization_min_max(X)
        # X = SVM_Feature_Select(X,Y, c=0.01)
        # X = Variance_Feature_Select(X)
        dataset = np.concatenate((Y, X), axis=1)
        k = 1
        correct = 0.0
        accuracy = 0.0
        fp = 0
        fn = 0
        tn = 0
        tp = 0
        trainingSet = dataset
        prevTestSetIndex = []
        prevTestSet = np.empty((1, 97))
        # print ('Predictions for Test.')
        index = 0
        for x in range(len(dataset)):
            split = float(len(trainingSet)-1)/len(trainingSet)
            # print "Split"+repr(split)
            trainingSet, testSet, i = splitDataset(trainingSet, split)
            # print 'Split Train: ' + repr(trainingSet)
            # print 'Split Test: ' + repr(testSet)
            # print 'Test index: ' + repr(i)
            if index != 0:
                trainingSet = np.concatenate((trainingSet, prevTestSet), axis=0)
            # print 'Concatenate Train: ' + repr(trainingSet)
            # print 'Concatenate Test: ' + repr(testSet)
            neighbors = getNeighbors(trainingSet, testSet[0], k)
            # prediction = getResponseDiscrete(neighbors)
            prediction = getResponseContinuous(neighbors)
            # print('> predicted=' + repr(prediction) + ":" + repr(type(prediction)) + ', actual=' + repr(testSet[0][0])) + ":" + repr(type(testSet[0][0]))
            
            # Discrete Predictions
            # if testSet[0][0] == prediction:
            #     correct += 1

            # if testSet[0][0] == 1.0 and prediction == -1.0:
            #     fp+=1
            # elif testSet[0][0] == -1.0 and prediction == 1.0:
            #     fn+=1
            # elif testSet[0][0] == 1.0 and prediction == 1.0:
            #     tp += 1
            # else:
            #     tn += 1

            #Continuous Predictions
            if testSet[0][0] > 0 and  prediction >= 0:
                correct += 1

            if testSet[0][0] < 0 and prediction < 0:
                correct +=1

            if testSet[0][0] >= 0 and prediction < 0:
                fp+=1
            if testSet[0][0] < 0 and prediction >= 0:
                fn+=1
            if testSet[0][0] >= 0 and prediction >= 0:
                tp += 1
            if testSet[0][0] < 0 and prediction < 0:
                tn += 1

            prevTestSetIndex.append(i)
            # print "Already Tested:"+repr(prevTestSetIndex)
            if index == 0:
                
                prevTestSet = testSet
            else:
                prevTestSet = np.concatenate((prevTestSet, testSet), axis = 0)
             
                trainingSet = np.delete(trainingSet, prevTestSetIndex, axis = 0)
            # print 'Diff Train: ' + repr(trainingSet)
            # print 'Diff Test: ' + repr(testSet)
            index += 1
            accuracy = correct/len(dataset) * 100.0
        avg_accuracy += accuracy
        avg_fp += fp
        avg_fn += fn
        avg_tp += tp
        avg_tn += tn

    # Collecting Results
    avg_accuracy = avg_accuracy/5
    accuracy = round(avg_accuracy, 2)
    fp = int(avg_fp/5)
    fn = int(avg_fn/5)
    tp = int(avg_tp/5)
    tn = int(avg_tn/5)

    print(repr(accuracy) + ',' + repr(fp) + ','+ repr(fn) + ',' +
     repr(tn) + ','+ repr(tp))
    
main()


