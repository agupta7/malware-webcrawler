"""
================================
Nearest Neighbors Classification
================================

Sample usage of Nearest Neighbors classification.
It will plot the decision boundaries for each class.
"""
print(__doc__)

import numpy as np
import csv
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn import neighbors

n_neighbors = 5

def Load_Data(filename):
    X = []
    Y = []
    with open (filename, "rb") as file:
        reader = csv.reader (file)
        for line in reader:
            Y.append (float(line[1]))
            line.pop(0)
            line.pop(0) 
            X.append (np.array(line , dtype=float))

    X = np.array(X)
    Y = np.array(Y,dtype=int)
    return X , Y

# random shuffel for samples
def shuffle_in_unison_scary(a, b):
        rng_state = np.random.get_state()
        np.random.shuffle(a)
        np.random.set_state(rng_state)
        np.random.shuffle(b)
        print "Shuffled"
        return a,b

#################### split data into training and testing, given the test data ratio
def split(ratio_tst, X, Y):
    print ratio_tst*len(Y)
    Xtest, X = np.split(X, [int(ratio_tst*len(Y))])
    Ytest, Y = np.split(Y, [int(ratio_tst*len(Y))])
    print "splitted"
    return Xtest,X,Ytest,Y

def getAccuracy(testSetClasses, predictions):
    correct = 0

    for x in range(len(testSetClasses)):
        if testSetClasses[x] == predictions[x]:
            correct += 1
    return (correct/float(len(testSetClasses))) * 100.0

def main():
    # prepare data
    X,Y = Load_Data('malware_dataset_old.csv')
    X,Y = shuffle_in_unison_scary(X, Y)
    Xtest, X, Ytest, Y = split(0.8, X, Y)

    h = .02  # step size in the mesh

    # Create color maps
    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])

    clf = neighbors.KNeighborsClassifier(n_neighbors, p=3)
    clf.fit(X, Y)


    # Plot the decision boundary. For that, we will assign a color to each
    # point in the mesh [x_min, x_max]x[y_min, y_max].
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    Z = clf.predict(X)

    # Put the result into a color plot
    # Z = Z.reshape(xx.shape)
    plt.figure()
    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

    # Plot also the training points
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,
                edgecolor='k', s=20)
    plt.xlim(xx.min(), xx.max())
    plt.ylim(yy.min(), yy.max())
    plt.title("3-Class classification (k = %i, weights = '%s')"
              % (n_neighbors, weights))

    plt.show()

    print getAccuracy(Ytest, Z)

main()


  
